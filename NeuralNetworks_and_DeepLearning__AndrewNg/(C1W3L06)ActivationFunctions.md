# Activation Function

NN을 만들 때 선택해야 하는 것 중 하나는 hidden layer와 output layer에서 어떤 activation function을 쓸 지 이다. 지금까지는 sigmoid 함수를 사용했지만, 다른 함수가 더 좋을 수도 있다.

### tanh function

![tanh](./img/tanhReal.gif)
$$ a=tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}$$

또한 다른 층에서는 다른 활성화함수가 사용될 수 있다.
