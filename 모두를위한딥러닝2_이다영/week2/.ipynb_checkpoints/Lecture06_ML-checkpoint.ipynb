{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "- H(x)=Wx\n",
    "- z=H(x), g(z)\n",
    "- g(z)=1/(1+e^-x) sigmoid 함수 \n",
    "    - 나오는 값이 0~1사이의 값 y햇(y는 실제 값, y햇은 예측값)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial classification\n",
    "성적 A, B, C 구분할 때\n",
    "- C인지 아닌지, B인지 아닌지, A인지 아닌지 구분하는 classification 3개를 만든다.\n",
    "- 독립적으로 세번 계산하기는 어렵다\n",
    "    - matrix형태로 바꿔 matrix multiplication으로 계산함\n",
    "    - 이렇게 나온 y햇a,b,c가 Ha,b,c(x)의 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMax\n",
    "- n개의 값을 softmax에 넣으면 각가 0~1사이의 확률이 나옴(result가 나올 확률)\n",
    "    - One Hot Encoding으로 0/1로 구분해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "### Cross-entropy cost function\n",
    "- 예측이 맞으면 작은 값이 되고\n",
    "- 예측이 틀리면 엄청 크게 된다.\n",
    "\n",
    "\n",
    "### Logistic cost vs cross entropy\n",
    "- 실제로는 같은 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "- Loss/Cost function이 어떤 점에서 시작하더라도 최소값에 도달할 수 있다.\n",
    "- 경사면을 미분(기울기)해서 점점 내려가 최소값을 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
